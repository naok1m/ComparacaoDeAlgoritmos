# AnÃ¡lise TeÃ³rica dos Algoritmos de OrdenaÃ§Ã£o

## ğŸ“š Fundamentos TeÃ³ricos

Este documento apresenta uma anÃ¡lise teÃ³rica detalhada dos algoritmos implementados no sistema.

---

## 1. Merge Sort

### DescriÃ§Ã£o
Algoritmo de ordenaÃ§Ã£o baseado na tÃ©cnica de **divisÃ£o e conquista**. Divide o array recursivamente em duas metades, ordena cada metade e depois as combina (merge).

### Complexidade de Tempo

| Caso | Complexidade | Justificativa |
|------|-------------|---------------|
| **Melhor** | O(n log n) | Sempre divide ao meio e faz n comparaÃ§Ãµes por nÃ­vel |
| **MÃ©dio** | O(n log n) | Mesmo comportamento independente da entrada |
| **Pior** | O(n log n) | Mesmo comportamento independente da entrada |

### Complexidade de EspaÃ§o
- **O(n)** - Requer arrays auxiliares para o merge

### AnÃ¡lise MatemÃ¡tica

1. **NÃºmero de divisÃµes**: logâ‚‚(n) nÃ­veis
2. **Trabalho por nÃ­vel**: O(n) comparaÃ§Ãµes e movimentos
3. **Total**: T(n) = 2T(n/2) + O(n) = O(n log n)

### RecorrÃªncia

```
T(n) = 2T(n/2) + Î˜(n)
```

Pelo **Teorema Mestre**:
- a = 2, b = 2, f(n) = Î˜(n)
- n^(log_b a) = n^1 = n
- Caso 2: T(n) = Î˜(n log n)

### CaracterÃ­sticas

| Propriedade | Valor |
|------------|-------|
| **EstÃ¡vel** | âœ… Sim |
| **In-place** | âŒ NÃ£o |
| **Adaptativo** | âŒ NÃ£o |
| **ComparaÃ§Ãµes** | ~n log n |
| **Movimentos** | ~2n log n |

### Vantagens
- âœ… Complexidade garantida O(n log n)
- âœ… EstÃ¡vel - mantÃ©m ordem de elementos iguais
- âœ… PrevisÃ­vel - desempenho consistente
- âœ… Bom para dados em disco (acesso sequencial)
- âœ… ParalelizÃ¡vel

### Desvantagens
- âŒ Requer O(n) de memÃ³ria extra
- âŒ NÃ£o Ã© in-place
- âŒ Overhead de cÃ³pias de arrays

### Quando Usar
- Quando estabilidade Ã© necessÃ¡ria
- Quando O(n log n) garantido Ã© importante
- Com listas encadeadas (sem overhead de espaÃ§o)
- Em ordenaÃ§Ã£o externa (dados em disco)
- Quando paralelizaÃ§Ã£o Ã© possÃ­vel

---

## 2. Heap Sort

### DescriÃ§Ã£o
Algoritmo baseado em **estrutura de heap** (Ã¡rvore binÃ¡ria implÃ­cita). ConstrÃ³i um max-heap e extrai repetidamente o mÃ¡ximo.

### Complexidade de Tempo

| Caso | Complexidade | Justificativa |
|------|-------------|---------------|
| **Melhor** | O(n log n) | ConstruÃ§Ã£o do heap + n extraÃ§Ãµes |
| **MÃ©dio** | O(n log n) | Mesmo comportamento |
| **Pior** | O(n log n) | Mesmo comportamento |

### Complexidade de EspaÃ§o
- **O(1)** - OrdenaÃ§Ã£o in-place

### AnÃ¡lise MatemÃ¡tica

1. **ConstruÃ§Ã£o do heap**: O(n)
   - Heapify de baixo para cima
   - Î£(i=0 to log n) 2^i Ã— (log n - i) = O(n)

2. **ExtraÃ§Ãµes**: n Ã— O(log n)
   - n elementos Ã— log n para heapify

3. **Total**: O(n) + n Ã— O(log n) = O(n log n)

### CaracterÃ­sticas

| Propriedade | Valor |
|------------|-------|
| **EstÃ¡vel** | âŒ NÃ£o |
| **In-place** | âœ… Sim |
| **Adaptativo** | âŒ NÃ£o |
| **ComparaÃ§Ãµes** | ~2n log n |
| **Movimentos** | ~n log n |

### Estrutura do Heap

Em um array, para o elemento no Ã­ndice `i`:
- Pai: `(i-1)/2`
- Filho esquerdo: `2i + 1`
- Filho direito: `2i + 2`

### Vantagens
- âœ… OrdenaÃ§Ã£o in-place (O(1) de espaÃ§o)
- âœ… Complexidade O(n log n) garantida
- âœ… Sem pior caso quadrÃ¡tico
- âœ… Bom para sistemas com memÃ³ria limitada

### Desvantagens
- âŒ NÃ£o estÃ¡vel
- âŒ Cache-unfriendly (acesso nÃ£o sequencial)
- âŒ Constante multiplicativa maior
- âŒ NÃ£o adaptativo

### Quando Usar
- Quando memÃ³ria Ã© limitada
- Quando O(n log n) garantido Ã© necessÃ¡rio
- Quando estabilidade nÃ£o importa
- Em sistemas embarcados

---

## 3. Quick Sort

### DescriÃ§Ã£o
Algoritmo baseado em **particionamento**. Escolhe um pivÃ´, particiona o array em elementos menores e maiores que o pivÃ´, e ordena recursivamente.

### Complexidade de Tempo

| Caso | Complexidade | Justificativa |
|------|-------------|---------------|
| **Melhor** | O(n log n) | PivÃ´ sempre divide ao meio |
| **MÃ©dio** | O(n log n) | PivÃ´ divide razoavelmente |
| **Pior** | O(nÂ²) | PivÃ´ sempre no extremo |

### Complexidade de EspaÃ§o
- **O(log n)** - Pilha de recursÃ£o (melhor caso)
- **O(n)** - Pilha de recursÃ£o (pior caso)

### AnÃ¡lise MatemÃ¡tica

**Caso MÃ©dio**:
```
T(n) = T(k) + T(n-k-1) + Î˜(n)
```
onde k Ã© o tamanho da partiÃ§Ã£o esquerda.

Assumindo particionamento equilibrado:
```
T(n) = 2T(n/2) + Î˜(n) = Î˜(n log n)
```

**Pior Caso** (pivÃ´ sempre no extremo):
```
T(n) = T(n-1) + Î˜(n) = Î˜(nÂ²)
```

### CaracterÃ­sticas

| Propriedade | Valor |
|------------|-------|
| **EstÃ¡vel** | âŒ NÃ£o (implementaÃ§Ã£o padrÃ£o) |
| **In-place** | âœ… Sim |
| **Adaptativo** | âš ï¸ Depende do pivÃ´ |
| **ComparaÃ§Ãµes** | ~n log n (mÃ©dio), nÂ²/2 (pior) |
| **Movimentos** | ~n log n/3 (mÃ©dio) |

### EstratÃ©gias de PivÃ´

#### 1. Ãšltimo Elemento
```
PivÃ´ = array[high]
```
- Simples de implementar
- **Pior caso**: dados ordenados ou reversos

#### 2. Primeiro Elemento
```
PivÃ´ = array[low]
```
- Simples de implementar
- **Pior caso**: dados ordenados

#### 3. Elemento do Meio
```
PivÃ´ = array[(low + high) / 2]
```
- Melhor que extremos
- Ainda vulnerÃ¡vel a padrÃµes

#### 4. Mediana de TrÃªs â­
```
PivÃ´ = mediana(array[low], array[mid], array[high])
```
- Melhor escolha na prÃ¡tica
- Reduz probabilidade de pior caso
- Overhead mÃ­nimo

### OtimizaÃ§Ãµes Implementadas

1. **Mediana de TrÃªs**: Melhora escolha do pivÃ´
2. **Particionamento de Hoare**: Eficiente em swaps

### Vantagens
- âœ… RÃ¡pido na prÃ¡tica (melhor constante multiplicativa)
- âœ… Cache-friendly (localidade de referÃªncia)
- âœ… In-place
- âœ… FÃ¡cil de paralelizar

### Desvantagens
- âŒ Pior caso O(nÂ²)
- âŒ NÃ£o estÃ¡vel
- âŒ SensÃ­vel Ã  escolha do pivÃ´
- âŒ RecursÃ£o profunda no pior caso

### Quando Usar
- Com dados aleatÃ³rios
- Quando velocidade mÃ©dia Ã© prioridade
- Com mediana de trÃªs ou randomizaÃ§Ã£o
- Quando memÃ³ria Ã© limitada

### Quando NÃƒO Usar
- Com dados jÃ¡ ordenados (sem mediana de trÃªs)
- Quando estabilidade Ã© necessÃ¡ria
- Quando pior caso O(nÂ²) Ã© inaceitÃ¡vel

---

## ğŸ“Š ComparaÃ§Ã£o Direta

### Tabela Comparativa

| CritÃ©rio | Merge Sort | Heap Sort | Quick Sort |
|----------|------------|-----------|------------|
| **Melhor caso** | O(n log n) | O(n log n) | O(n log n) |
| **Caso mÃ©dio** | O(n log n) | O(n log n) | O(n log n) |
| **Pior caso** | O(n log n) | O(n log n) | **O(nÂ²)** |
| **EspaÃ§o** | O(n) | **O(1)** | O(log n) |
| **EstÃ¡vel** | **Sim** | NÃ£o | NÃ£o |
| **In-place** | NÃ£o | **Sim** | **Sim** |
| **ComparaÃ§Ãµes** | ~n log n | ~2n log n | ~1.4n log n |
| **Cache** | MÃ©dio | Ruim | **Bom** |
| **ImplementaÃ§Ã£o** | MÃ©dia | MÃ©dia | Simples |

### AnÃ¡lise de CenÃ¡rios

#### Dados AleatÃ³rios
1. **Quick Sort** (mediana de trÃªs) - Mais rÃ¡pido â­
2. **Heap Sort** - Competitivo
3. **Merge Sort** - Mais lento

**Por quÃª?** Quick Sort tem melhor localidade de cache.

#### Dados Quase Ordenados
1. **Quick Sort** (mediana de trÃªs) - Bom â­
2. **Merge Sort** - Consistente
3. **Heap Sort** - Sem mudanÃ§a

**Por quÃª?** Quick Sort adapta-se bem com boa escolha de pivÃ´.

#### Dados Reversos
1. **Heap Sort** - Melhor â­
2. **Merge Sort** - Consistente
3. **Quick Sort** (Ãºltimo pivÃ´) - **MUITO RUIM** (O(nÂ²))

**Por quÃª?** Quick Sort com pivÃ´ no final tem pior caso.

#### Dados com RepetiÃ§Ãµes
1. **Quick Sort** - RÃ¡pido â­
2. **Heap Sort** - Bom
3. **Merge Sort** - Mais lento

**Por quÃª?** Muitas igualdades favorecem particionamento.

---

## ğŸ¯ Guia de DecisÃ£o

### Escolha Merge Sort quando:
- âœ… Estabilidade Ã© **essencial**
- âœ… Precisa de **desempenho garantido**
- âœ… MemÃ³ria nÃ£o Ã© problema
- âœ… Ordenando listas encadeadas
- âœ… OrdenaÃ§Ã£o externa (dados em disco)

### Escolha Heap Sort quando:
- âœ… MemÃ³ria Ã© **limitada**
- âœ… Precisa de **O(n log n) garantido**
- âœ… Estabilidade **nÃ£o importa**
- âœ… Pior caso O(nÂ²) Ã© **inaceitÃ¡vel**

### Escolha Quick Sort quando:
- âœ… Velocidade **mÃ©dia** Ã© prioridade
- âœ… Dados sÃ£o **aleatÃ³rios**
- âœ… Use **mediana de trÃªs**
- âœ… MemÃ³ria Ã© limitada
- âŒ MAS estabilidade nÃ£o Ã© necessÃ¡ria
- âŒ E pior caso raro Ã© aceitÃ¡vel

---

## ğŸ“ˆ AnÃ¡lise AssintÃ³tica

### NotaÃ§Ã£o Big-O

- **O(f(n))**: Limite superior (pior caso)
- **Î©(f(n))**: Limite inferior (melhor caso)  
- **Î˜(f(n))**: Limite justo (ordem exata)

### Crescimento de FunÃ§Ãµes

Para n = 1.000.000:

| FunÃ§Ã£o | OperaÃ§Ãµes | Exemplo |
|--------|-----------|---------|
| O(n) | 1.000.000 | Busca linear |
| O(n log n) | ~20.000.000 | Merge/Heap/Quick Sort |
| O(nÂ²) | 1.000.000.000.000 | Quick Sort pior caso |

**DiferenÃ§a entre O(nÂ²) e O(n log n)**:
- Para n = 1.000: 50x mais rÃ¡pido
- Para n = 10.000: 664x mais rÃ¡pido
- Para n = 100.000: 8.333x mais rÃ¡pido

---

## ğŸ“š ReferÃªncias TeÃ³ricas

1. **Cormen, T. H., et al.** (2009). *Introduction to Algorithms* (3rd ed.). MIT Press.
   - CapÃ­tulo 2: Insertion Sort, Merge Sort
   - CapÃ­tulo 6: Heapsort
   - CapÃ­tulo 7: Quicksort

2. **Knuth, D. E.** (1998). *The Art of Computer Programming, Volume 3: Sorting and Searching* (2nd ed.). Addison-Wesley.

3. **Sedgewick, R., & Wayne, K.** (2011). *Algorithms* (4th ed.). Addison-Wesley.

4. **Skiena, S. S.** (2008). *The Algorithm Design Manual* (2nd ed.). Springer.

---

## ğŸ”¬ ValidaÃ§Ã£o Experimental

Este sistema permite validar experimentalmente as anÃ¡lises teÃ³ricas:

1. **Confirmar complexidades**: Observar crescimento dos tempos
2. **Identificar constantes**: Fatores multiplicativos
3. **Analisar distribuiÃ§Ãµes**: Impacto dos dados
4. **Testar otimizaÃ§Ãµes**: Mediana de trÃªs vs Ãºltimo elemento

---

## ğŸ’¡ Insights TeÃ³ricos

### 1. Por que O(n log n) Ã© Ã³timo?
Para ordenaÃ§Ã£o por comparaÃ§Ã£o, o limite inferior Ã© **Î©(n log n)**.

**Prova**: Ãrvore de decisÃ£o com n! folhas tem altura â‰¥ logâ‚‚(n!) = Î©(n log n).

### 2. Trade-offs fundamentais
- **Estabilidade** vs **In-place**: DifÃ­cil ter ambos
- **Pior caso** vs **Caso mÃ©dio**: Quick Sort troca garantias por velocidade
- **MemÃ³ria** vs **Velocidade**: Merge Sort usa mais memÃ³ria para consistÃªncia

### 3. Constantes multiplicativas importam!
Mesmo com mesma complexidade O(n log n):
- Quick Sort: ~1.4n log n comparaÃ§Ãµes
- Merge Sort: ~n log n comparaÃ§Ãµes
- Heap Sort: ~2n log n comparaÃ§Ãµes

Na prÃ¡tica, Quick Sort costuma ser mais rÃ¡pido pelo cache.

---

**Use este documento como referÃªncia para entender os resultados experimentais!**

