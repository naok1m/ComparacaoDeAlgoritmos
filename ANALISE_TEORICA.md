# An√°lise Te√≥rica dos Algoritmos de Ordena√ß√£o

## üìö Fundamentos Te√≥ricos

Este documento apresenta uma an√°lise te√≥rica detalhada dos algoritmos implementados no sistema.

---

## 1. Merge Sort

### Descri√ß√£o
Algoritmo de ordena√ß√£o baseado na t√©cnica de **divis√£o e conquista**. Divide o array recursivamente em duas metades, ordena cada metade e depois as combina (merge).

### Complexidade de Tempo

| Caso | Complexidade | Justificativa |
|------|-------------|---------------|
| **Melhor** | O(n log n) | Sempre divide ao meio e faz n compara√ß√µes por n√≠vel |
| **M√©dio** | O(n log n) | Mesmo comportamento independente da entrada |
| **Pior** | O(n log n) | Mesmo comportamento independente da entrada |

### Complexidade de Espa√ßo
- **O(n)** - Requer arrays auxiliares para o merge

### An√°lise Matem√°tica

1. **N√∫mero de divis√µes**: log‚ÇÇ(n) n√≠veis
2. **Trabalho por n√≠vel**: O(n) compara√ß√µes e movimentos
3. **Total**: T(n) = 2T(n/2) + O(n) = O(n log n)

### Recorr√™ncia

```
T(n) = 2T(n/2) + Œò(n)
```

Pelo **Teorema Mestre**:
- a = 2, b = 2, f(n) = Œò(n)
- n^(log_b a) = n^1 = n
- Caso 2: T(n) = Œò(n log n)

### Caracter√≠sticas

| Propriedade | Valor |
|------------|-------|
| **Est√°vel** | ‚úÖ Sim |
| **In-place** | ‚ùå N√£o |
| **Adaptativo** | ‚ùå N√£o |
| **Compara√ß√µes** | ~n log n |
| **Movimentos** | ~2n log n |

### Vantagens
- ‚úÖ Complexidade garantida O(n log n)
- ‚úÖ Est√°vel - mant√©m ordem de elementos iguais
- ‚úÖ Previs√≠vel - desempenho consistente
- ‚úÖ Bom para dados em disco (acesso sequencial)
- ‚úÖ Paraleliz√°vel

### Desvantagens
- ‚ùå Requer O(n) de mem√≥ria extra
- ‚ùå N√£o √© in-place
- ‚ùå Overhead de c√≥pias de arrays

### Quando Usar
- Quando estabilidade √© necess√°ria
- Quando O(n log n) garantido √© importante
- Com listas encadeadas (sem overhead de espa√ßo)
- Em ordena√ß√£o externa (dados em disco)
- Quando paraleliza√ß√£o √© poss√≠vel

---

## 2. Heap Sort

### Descri√ß√£o
Algoritmo baseado em **estrutura de heap** (√°rvore bin√°ria impl√≠cita). Constr√≥i um max-heap e extrai repetidamente o m√°ximo.

### Complexidade de Tempo

| Caso | Complexidade | Justificativa |
|------|-------------|---------------|
| **Melhor** | O(n log n) | Constru√ß√£o do heap + n extra√ß√µes |
| **M√©dio** | O(n log n) | Mesmo comportamento |
| **Pior** | O(n log n) | Mesmo comportamento |

### Complexidade de Espa√ßo
- **O(1)** - Ordena√ß√£o in-place

### An√°lise Matem√°tica

1. **Constru√ß√£o do heap**: O(n)
   - Heapify de baixo para cima
   - Œ£(i=0 to log n) 2^i √ó (log n - i) = O(n)

2. **Extra√ß√µes**: n √ó O(log n)
   - n elementos √ó log n para heapify

3. **Total**: O(n) + n √ó O(log n) = O(n log n)

### Caracter√≠sticas

| Propriedade | Valor |
|------------|-------|
| **Est√°vel** | ‚ùå N√£o |
| **In-place** | ‚úÖ Sim |
| **Adaptativo** | ‚ùå N√£o |
| **Compara√ß√µes** | ~2n log n |
| **Movimentos** | ~n log n |

### Estrutura do Heap

Em um array, para o elemento no √≠ndice `i`:
- Pai: `(i-1)/2`
- Filho esquerdo: `2i + 1`
- Filho direito: `2i + 2`

### Vantagens
- ‚úÖ Ordena√ß√£o in-place (O(1) de espa√ßo)
- ‚úÖ Complexidade O(n log n) garantida
- ‚úÖ Sem pior caso quadr√°tico
- ‚úÖ Bom para sistemas com mem√≥ria limitada

### Desvantagens
- ‚ùå N√£o est√°vel
- ‚ùå Cache-unfriendly (acesso n√£o sequencial)
- ‚ùå Constante multiplicativa maior
- ‚ùå N√£o adaptativo

### Quando Usar
- Quando mem√≥ria √© limitada
- Quando O(n log n) garantido √© necess√°rio
- Quando estabilidade n√£o importa
- Em sistemas embarcados

---

## 3. Quick Sort

### Descri√ß√£o
Algoritmo baseado em **particionamento**. Escolhe um piv√¥, particiona o array em elementos menores e maiores que o piv√¥, e ordena recursivamente.

### Complexidade de Tempo

| Caso | Complexidade | Justificativa |
|------|-------------|---------------|
| **Melhor** | O(n log n) | Piv√¥ sempre divide ao meio |
| **M√©dio** | O(n log n) | Piv√¥ divide razoavelmente |
| **Pior** | O(n¬≤) | Piv√¥ sempre no extremo |

### Complexidade de Espa√ßo
- **O(log n)** - Pilha de recurs√£o (melhor caso)
- **O(n)** - Pilha de recurs√£o (pior caso)

### An√°lise Matem√°tica

**Caso M√©dio**:
```
T(n) = T(k) + T(n-k-1) + Œò(n)
```
onde k √© o tamanho da parti√ß√£o esquerda.

Assumindo particionamento equilibrado:
```
T(n) = 2T(n/2) + Œò(n) = Œò(n log n)
```

**Pior Caso** (piv√¥ sempre no extremo):
```
T(n) = T(n-1) + Œò(n) = Œò(n¬≤)
```

### Caracter√≠sticas

| Propriedade | Valor |
|------------|-------|
| **Est√°vel** | ‚ùå N√£o (implementa√ß√£o padr√£o) |
| **In-place** | ‚úÖ Sim |
| **Adaptativo** | ‚ö†Ô∏è Depende do piv√¥ |
| **Compara√ß√µes** | ~n log n (m√©dio), n¬≤/2 (pior) |
| **Movimentos** | ~n log n/3 (m√©dio) |

### Estrat√©gias de Piv√¥

#### 1. √öltimo Elemento
```
Piv√¥ = array[high]
```
- Simples de implementar
- **Pior caso**: dados ordenados ou reversos

#### 2. Primeiro Elemento
```
Piv√¥ = array[low]
```
- Simples de implementar
- **Pior caso**: dados ordenados

#### 3. Elemento do Meio
```
Piv√¥ = array[(low + high) / 2]
```
- Melhor que extremos
- Ainda vulner√°vel a padr√µes

#### 4. Mediana de Tr√™s ‚≠ê
```
Piv√¥ = mediana(array[low], array[mid], array[high])
```
- Melhor escolha na pr√°tica
- Reduz probabilidade de pior caso
- Overhead m√≠nimo

### Otimiza√ß√µes Implementadas

1. **Mediana de Tr√™s**: Melhora escolha do piv√¥
2. **Particionamento de Hoare**: Eficiente em swaps

### Vantagens
- ‚úÖ R√°pido na pr√°tica (melhor constante multiplicativa)
- ‚úÖ Cache-friendly (localidade de refer√™ncia)
- ‚úÖ In-place
- ‚úÖ F√°cil de paralelizar

### Desvantagens
- ‚ùå Pior caso O(n¬≤)
- ‚ùå N√£o est√°vel
- ‚ùå Sens√≠vel √† escolha do piv√¥
- ‚ùå Recurs√£o profunda no pior caso

### Quando Usar
- Com dados aleat√≥rios
- Quando velocidade m√©dia √© prioridade
- Com mediana de tr√™s ou randomiza√ß√£o
- Quando mem√≥ria √© limitada

### Quando N√ÉO Usar
- Com dados j√° ordenados (sem mediana de tr√™s)
- Quando estabilidade √© necess√°ria
- Quando pior caso O(n¬≤) √© inaceit√°vel

---

## üìä Compara√ß√£o Direta

### Tabela Comparativa

| Crit√©rio | Merge Sort | Heap Sort | Quick Sort |
|----------|------------|-----------|------------|
| **Melhor caso** | O(n log n) | O(n log n) | O(n log n) |
| **Caso m√©dio** | O(n log n) | O(n log n) | O(n log n) |
| **Pior caso** | O(n log n) | O(n log n) | **O(n¬≤)** |
| **Espa√ßo** | O(n) | **O(1)** | O(log n) |
| **Est√°vel** | **Sim** | N√£o | N√£o |
| **In-place** | N√£o | **Sim** | **Sim** |
| **Compara√ß√µes** | ~n log n | ~2n log n | ~1.4n log n |
| **Cache** | M√©dio | Ruim | **Bom** |
| **Implementa√ß√£o** | M√©dia | M√©dia | Simples |

### An√°lise de Cen√°rios

#### Dados Aleat√≥rios
1. **Quick Sort** (mediana de tr√™s) - Mais r√°pido ‚≠ê
2. **Heap Sort** - Competitivo
3. **Merge Sort** - Mais lento

**Por qu√™?** Quick Sort tem melhor localidade de cache.

#### Dados Quase Ordenados
1. **Quick Sort** (mediana de tr√™s) - Bom ‚≠ê
2. **Merge Sort** - Consistente
3. **Heap Sort** - Sem mudan√ßa

**Por qu√™?** Quick Sort adapta-se bem com boa escolha de piv√¥.

#### Dados Reversos
1. **Heap Sort** - Melhor ‚≠ê
2. **Merge Sort** - Consistente
3. **Quick Sort** (√∫ltimo piv√¥) - **MUITO RUIM** (O(n¬≤))

**Por qu√™?** Quick Sort com piv√¥ no final tem pior caso.

#### Dados com Repeti√ß√µes
1. **Quick Sort** - R√°pido ‚≠ê
2. **Heap Sort** - Bom
3. **Merge Sort** - Mais lento

**Por qu√™?** Muitas igualdades favorecem particionamento.

---

## üéØ Guia de Decis√£o

### Escolha Merge Sort quando:
- ‚úÖ Estabilidade √© **essencial**
- ‚úÖ Precisa de **desempenho garantido**
- ‚úÖ Mem√≥ria n√£o √© problema
- ‚úÖ Ordenando listas encadeadas
- ‚úÖ Ordena√ß√£o externa (dados em disco)

### Escolha Heap Sort quando:
- ‚úÖ Mem√≥ria √© **limitada**
- ‚úÖ Precisa de **O(n log n) garantido**
- ‚úÖ Estabilidade **n√£o importa**
- ‚úÖ Pior caso O(n¬≤) √© **inaceit√°vel**

### Escolha Quick Sort quando:
- ‚úÖ Velocidade **m√©dia** √© prioridade
- ‚úÖ Dados s√£o **aleat√≥rios**
- ‚úÖ Use **mediana de tr√™s**
- ‚úÖ Mem√≥ria √© limitada
- ‚ùå MAS estabilidade n√£o √© necess√°ria
- ‚ùå E pior caso raro √© aceit√°vel

---

## üìà An√°lise Assint√≥tica

### Nota√ß√£o Big-O

- **O(f(n))**: Limite superior (pior caso)
- **Œ©(f(n))**: Limite inferior (melhor caso)  
- **Œò(f(n))**: Limite justo (ordem exata)

### Crescimento de Fun√ß√µes

Para n = 1.000.000:

| Fun√ß√£o | Opera√ß√µes | Exemplo |
|--------|-----------|---------|
| O(n) | 1.000.000 | Busca linear |
| O(n log n) | ~20.000.000 | Merge/Heap/Quick Sort |
| O(n¬≤) | 1.000.000.000.000 | Quick Sort pior caso |

**Diferen√ßa entre O(n¬≤) e O(n log n)**:
- Para n = 1.000: 50x mais r√°pido
- Para n = 10.000: 664x mais r√°pido
- Para n = 100.000: 8.333x mais r√°pido

---

## üìö Refer√™ncias Te√≥ricas

1. **Cormen, T. H., et al.** (2009). *Introduction to Algorithms* (3rd ed.). MIT Press.
   - Cap√≠tulo 2: Insertion Sort, Merge Sort
   - Cap√≠tulo 6: Heapsort
   - Cap√≠tulo 7: Quicksort

2. **Knuth, D. E.** (1998). *The Art of Computer Programming, Volume 3: Sorting and Searching* (2nd ed.). Addison-Wesley.

3. **Sedgewick, R., & Wayne, K.** (2011). *Algorithms* (4th ed.). Addison-Wesley.

4. **Skiena, S. S.** (2008). *The Algorithm Design Manual* (2nd ed.). Springer.

---

## üî¨ Valida√ß√£o Experimental

Este sistema permite validar experimentalmente as an√°lises te√≥ricas:

1. **Confirmar complexidades**: Observar crescimento dos tempos
2. **Identificar constantes**: Fatores multiplicativos
3. **Analisar distribui√ß√µes**: Impacto dos dados
4. **Testar otimiza√ß√µes**: Mediana de tr√™s vs √∫ltimo elemento

---

## üí° Insights Te√≥ricos

### 1. Por que O(n log n) √© √≥timo?
Para ordena√ß√£o por compara√ß√£o, o limite inferior √© **Œ©(n log n)**.

**Prova**: √Årvore de decis√£o com n! folhas tem altura ‚â• log‚ÇÇ(n!) = Œ©(n log n).

### 2. Trade-offs fundamentais
- **Estabilidade** vs **In-place**: Dif√≠cil ter ambos
- **Pior caso** vs **Caso m√©dio**: Quick Sort troca garantias por velocidade
- **Mem√≥ria** vs **Velocidade**: Merge Sort usa mais mem√≥ria para consist√™ncia

### 3. Constantes multiplicativas importam!
Mesmo com mesma complexidade O(n log n):
- Quick Sort: ~1.4n log n compara√ß√µes
- Merge Sort: ~n log n compara√ß√µes
- Heap Sort: ~2n log n compara√ß√µes

Na pr√°tica, Quick Sort costuma ser mais r√°pido pelo cache.

---

**Use este documento como refer√™ncia para entender os resultados experimentais!**

